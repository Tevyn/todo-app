# Rule: Generating a Task List from a PRD

## Goal

To guide an AI assistant in creating a detailed, step-by-step task list in Markdown format based on an existing Product Requirements Document (PRD). The task list should guide a developer through implementation using Test-Driven Development (TDD) principles with small, focused iterations.

## Output

- **Format:** Markdown (`.md`)
- **Location:** `/tasks/`
- **Filename:** `tasks-[prd-file-name].md` (e.g., `tasks-prd-user-profile-editing.md`)

## Process

1.  **Receive PRD Reference:** The user points the AI to a specific PRD file
2.  **Analyze PRD:** The AI reads and analyzes the functional requirements, user stories, and other sections of the specified PRD.
3.  **Phase 1: Generate Parent Tasks:** Based on the PRD analysis, create the file and generate the main, high-level tasks required to implement the feature. Use your judgement on how many high-level tasks to use. It's likely to be about 5. Present these tasks to the user in the specified format (without sub-tasks yet). Inform the user: "I have generated the high-level tasks based on the PRD. Ready to generate the sub-tasks? Respond with 'Go' to proceed."
4.  **Wait for Confirmation:** Pause and wait for the user to respond with "Go".
5.  **Phase 2: Generate Sub-Tasks:** Once the user confirms, break down each parent task into smaller test-implement cycles. **CRITICAL:** Structure sub-tasks as paired test-then-implement steps for each piece of functionality.
6.  **Identify Relevant Files:** Based on the tasks and PRD, identify potential files that will need to be created or modified. List these under the `Relevant Files` section, including corresponding test files if applicable.
7.  **Generate Final Output:** Combine the parent tasks, sub-tasks, relevant files, and notes into the final Markdown structure.
8.  **Save Task List:** Save the generated document in the `/tasks/` directory with the filename `tasks-[prd-file-name].md`.

## Output Format

The generated task list _must_ follow this structure:

```markdown
## Relevant Files

- `path/to/potential/file1.ts` - Brief description of why this file is relevant (e.g., Contains the main component for this feature).
- `path/to/file1.test.ts` - Unit tests for `file1.ts`.
- `path/to/another/file.tsx` - Brief description (e.g., API route handler for data submission).
- `path/to/another/file.test.tsx` - Unit tests for `another/file.tsx`.
- `lib/utils/helpers.ts` - Brief description (e.g., Utility functions needed for calculations).
- `lib/utils/helpers.test.ts` - Unit tests for `helpers.ts`.

### Notes

- **TDD Approach:** Follow small red-green cycles. Write tests for ONE piece of functionality, then implement it immediately.
- **Git Commits:** After each successful implementation (green phase), commit with descriptive message.
- Unit tests should typically be placed alongside the code files they are testing.
- Use `npx jest [optional/path/to/test/file]` to run tests.
- For UI features, use Playwright to capture screenshots after implementation to verify visual changes.

## Tasks

- [ ] 1.0 Parent Task Title
  - [ ] 1.1 Write tests for [specific functionality A]
  - [ ] 1.2 Implement [functionality A] to pass tests
  - [ ] 1.3 Write tests for [specific functionality B]
  - [ ] 1.4 Implement [functionality B] to pass tests
  - [ ] 1.5 Refactor and optimize implementation
- [ ] 2.0 Parent Task Title (UI Feature)
  - [ ] 2.1 Write tests for component rendering
  - [ ] 2.2 Implement basic component structure
  - [ ] 2.3 Write tests for user interactions
  - [ ] 2.4 Implement interaction handlers
  - [ ] 2.5 Capture screenshot with Playwright to verify UI
  - [ ] 2.6 Write tests for edge cases
  - [ ] 2.7 Handle edge cases in implementation
- [ ] 3.0 Parent Task Title (may not require sub-tasks if purely structural or configuration)
```

## TDD Task Structure Guidelines

When generating sub-tasks for implementation work:

1. **Pair tests with implementation:** Each test-writing task should be immediately followed by its implementation task
2. **Small increments:** Each test/implement pair should focus on ONE specific behavior or functionality
3. **UI verification:** For UI features, include screenshot capture tasks after implementation
4. **Commit points:** Implementation tasks that make tests pass are natural commit points

Example patterns:
- For a new function: Test behavior A → Implement A → Test behavior B → Implement B → Refactor
- For a UI component: Test render → Implement render → Test interaction → Implement interaction → Screenshot verification
- For an API endpoint: Test success case → Implement success → Test error case → Implement error handling

## Interaction Model

The process explicitly requires a pause after generating parent tasks to get user confirmation ("Go") before proceeding to generate the detailed sub-tasks. This ensures the high-level plan aligns with user expectations before diving into details.

## Target Audience

Assume the primary reader of the task list is a **junior developer** who will implement the feature following TDD principles with frequent commits.